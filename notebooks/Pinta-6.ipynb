{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "[Keras] (https://keras.io/) es una librería de alto nivel que facilita la rápida experimentación utilizando Deep Learning. Soporta diversos backends, como tensorflow, theano, y CNTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = load_data()\n",
    "x_train = np.expand_dims(x_train, axis=-1) / 127.5 - 1\n",
    "x_test = np.expand_dims(x_test, axis=-1) / 127.5 - 1 \n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "i = Input(shape=(28, 28, 1))\n",
    "d = Conv2D(10, (3, 3))(i)\n",
    "d = Conv2D(10, (5, 5), strides=(2, 2))(d)\n",
    "d = Flatten()(d)\n",
    "d = Dense(100)(d)\n",
    "d = Dense(10, activation='softmax')(d)\n",
    "\n",
    "model = Model(inputs=i, outputs=d)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=1000, verbose=1, validation_data=(x_test, y_test))\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "Word Embeddings es una técnica que consiste en asignarle a cada palabra un vector de características que representa el concepto asociado a la palabra. En el siguiente ejemplo, utilizaremos el modelo preentrenado utilizando la técnica Word2Vec[1] utilizando artículos de [Google News](https://code.google.com/archive/p/word2vec/). \n",
    "\n",
    "[1] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient Estimation of Word Representations in Vector Space. In Proceedings of Workshop at ICLR, 2013.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import gensim\n",
    "\n",
    "model_wv = gensim.models.KeyedVectors.load_word2vec_format('d:\\GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['king', 'queen', 'man', 'woman']\n",
    "print('Vector king: {}'.format(model_wv['king']))\n",
    "\n",
    "vec = np.empty((4, 300))\n",
    "for i, w in enumerate(words):\n",
    "    vec[i, :] = model_wv[w]\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "x = TSNE().fit_transform(vec)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x[:, 0], x[:, 1])\n",
    "for i, w in enumerate(words):\n",
    "    ax.annotate(w, (x[i, 0], x[i, 1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_wv.most_similar(positive=['king', 'woman'], negative=['man']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement learning\n",
    "Open IA Gym example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "env = gym.make('Breakout-v0')\n",
    "env.reset()\n",
    "for i in range(100):\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "    observation, reward, done, info = env.step(env.action_space.sample())\n",
    "    if (i % 10 == 0):\n",
    "        print('Observation: {}\\nReward: {}\\nDone: {}'.format(observation.shape, reward, done))\n",
    "    if done:\n",
    "        print('Reseting...')\n",
    "        print('Observation: {}\\nReward: {}\\nDone: {}'.format(observation.shape, reward, done))\n",
    "        env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargando el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, BoltzmannQPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
    "\n",
    "\n",
    "class AtariProcessor(Processor):\n",
    "    def process_observation(self, observation):\n",
    "        assert observation.ndim == 3  # (height, width, channel)\n",
    "        img = Image.fromarray(observation)\n",
    "        img = img.resize(INPUT_SHAPE).convert('L')  # resize and convert to grayscale\n",
    "        processed_observation = np.array(img)\n",
    "        assert processed_observation.shape == INPUT_SHAPE\n",
    "        return processed_observation.astype('uint8')  # saves storage in experience memory\n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "        # We could perform this processing step in `process_observation`. In this case, however,\n",
    "        # we would need to store a `float32` array instead, which is 4x more memory intensive than\n",
    "        # an `uint8` array. This matters if we store 1M observations.\n",
    "        processed_batch = batch.astype('float32') / 255.\n",
    "        return processed_batch\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        return np.clip(reward, -1., 1.)\n",
    "\n",
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "\n",
    "INPUT_SHAPE = (84, 84)\n",
    "WINDOW_LENGTH = 4\n",
    "\n",
    "nb_actions = env.action_space.n\n",
    "env.close()\n",
    "\n",
    "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
    "model = Sequential()\n",
    "if K.image_dim_ordering() == 'tf':\n",
    "    # (width, height, channels)\n",
    "    model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
    "elif K.image_dim_ordering() == 'th':\n",
    "    # (channels, width, height)\n",
    "    model.add(Permute((1, 2, 3), input_shape=input_shape))\n",
    "else:\n",
    "    raise RuntimeError('Unknown image_dim_ordering.')\n",
    "model.add(Convolution2D(32, (8, 8), strides=(4, 4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (4, 4), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (3, 3), strides=(1, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())\n",
    "\n",
    "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n",
    "processor = AtariProcessor()\n",
    "\n",
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.05,\n",
    "                              nb_steps=1000000)\n",
    "\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, policy=policy, memory=memory,\n",
    "               processor=processor, nb_steps_warmup=50000, gamma=.99, target_model_update=10000,\n",
    "               train_interval=4, delta_clip=1.)\n",
    "dqn.compile(Adam(lr=.00025), metrics=['mae'])\n",
    "\n",
    "dqn.load_weights('dqn_BreakoutDeterministic-v4_weights_1750000.h5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "dqn.test(env, nb_episodes=5, visualize=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Captioning\n",
    "La red fue entrenada utilizando [IARP 2012](https://www.imageclef.org/photodata). \n",
    "* Para utilizar el modelo preentrenado, descargarlo de [aqui](https://mega.nz/#!4spxAQCL!KqQPiPYoK3xkwvccbhVVewQojt7WiSuDJ4x92sGaQvc).\n",
    "* Para realizar el entrenamiento bajar el dataset y descomprimirlo en la carpeta dataset. Luego ejecutar:\n",
    "\n",
    "```python preprocess.py```\n",
    "Para entrenar: \n",
    "```python train.py```\n",
    "\n",
    "Prediciendo captions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargando modelos\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras.applications import InceptionV3\n",
    "from preprocess import preprocess_image\n",
    "from model import ImageGen, start_token, end_token\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "print('Loading Models')\n",
    "img_model = InceptionV3(include_top=False)\n",
    "model = load_model('D:\\PycharmProjects\\caption2\\weights.1600-1.74.hdf5')\n",
    "data_gen = ImageGen('D:\\PycharmProjects\\caption2\\images_features', 'D:\\PycharmProjects\\caption2\\images_captions', caption_max_len=30, min_reps=2)\n",
    "print('Models Load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sentence(x):\n",
    "    res = []\n",
    "    prev = None\n",
    "    for v in x:\n",
    "        if v != prev:\n",
    "            res.append(v)\n",
    "            prev = v\n",
    "    return res\n",
    "\n",
    "def text_gen(img_features, model, words_ids, ids_words, caption_len):\n",
    "    x_img = np.expand_dims(img_features, axis=0)\n",
    "    x_cap = np.zeros((1, caption_len, len(words_ids)), dtype=np.float32)\n",
    "    predicted = [words_ids[start_token]]\n",
    "    end_id = words_ids[end_token]\n",
    "    x_cap[0, 0, words_ids[start_token]] = 1\n",
    "    for i in range(0, caption_len - 1):\n",
    "        pred = model.predict([x_cap, x_img])[0, :, :]\n",
    "        x_cap[0, i + 1, :] = pred[i, :] \n",
    "        pred_val = np.argmax(pred[i, :])\n",
    "        predicted.append(pred_val)\n",
    "        if pred_val == end_id:\n",
    "            break\n",
    "    return to_sentence([ids_words[i] for i in predicted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'D:/PycharmProjects/caption2/dataset/iaprtc12/images/00/116.jpg'\n",
    "img_path = 'D:/PycharmProjects/caption2/dataset/iaprtc12/images/18/18101.jpg'\n",
    "img = preprocess_image(img_model, img_path)\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "plt.imshow(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_gen(img, model, data_gen.word_id, data_gen.id_words, 30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
